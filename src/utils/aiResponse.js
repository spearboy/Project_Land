const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY
const GEMINI_API_BASE = 'https://generativelanguage.googleapis.com/v1beta'

const REQUEST_COOLDOWN = 5000
const lastRequestTime = new Map()

const getRandomFallbackResponse = () => {
  const fallbacks = [
    'ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°€ì›Œìš” ğŸ˜Š',
    'ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ì–´ë• ë‚˜ìš”?',
    'ì¬ë¯¸ìˆëŠ” ì´ì•¼ê¸°ë„¤ìš”!',
    'ê·¸ë ‡êµ°ìš”, ì´í•´í–ˆì–´ìš”.',
    'ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!',
  ]
  return fallbacks[Math.floor(Math.random() * fallbacks.length)]
}

const getAvailableModel = async () => {
  if (!GEMINI_API_KEY) return null

  try {
    const response = await fetch(`${GEMINI_API_BASE}/models?key=${GEMINI_API_KEY}`)
    if (response.ok) {
      const data = await response.json()
      const models = data.models || []
      
      const preferredModels = [
        'gemini-2.5-flash',
        'gemini-2.0-flash',
        'gemini-flash-latest',
        'gemini-2.5-pro',
        'gemini-pro-latest',
        'gemini-pro',
      ]
      
      for (const modelName of preferredModels) {
        const model = models.find(m => {
          const name = m.name || ''
          return name.includes(modelName) && m.supportedGenerationMethods?.includes('generateContent')
        })
        if (model) {
          const fullName = model.name
          console.log('ì„ íƒëœ ëª¨ë¸:', model.displayName, '(ì „ì²´ ì´ë¦„:', fullName, ')')
          return fullName
        }
      }
      
      const firstModel = models.find(m => m.supportedGenerationMethods?.includes('generateContent'))
      if (firstModel) {
        const fullName = firstModel.name
        console.log('ê¸°ë³¸ ëª¨ë¸ ì„ íƒ:', firstModel.displayName, '(ì „ì²´ ì´ë¦„:', fullName, ')')
        return fullName
      }
    } else {
      const errorData = await response.json().catch(() => ({}))
      console.error('ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:', response.status, errorData)
    }
  } catch (error) {
    console.error('ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜:', error)
  }
  
  console.warn('ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.')
  return 'models/gemini-2.5-flash'
}

let cachedModel = null

const generateAIResponse = async (userMessage, roomName, roomId) => {
  if (!GEMINI_API_KEY) {
    console.warn('Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.')
    return getRandomFallbackResponse()
  }

  const now = Date.now()
  const lastRequest = lastRequestTime.get(roomId) || 0
  
  if (now - lastRequest < REQUEST_COOLDOWN) {
    console.log('AI ìš”ì²­ ì¿¨ë‹¤ìš´ ì¤‘...')
    return getRandomFallbackResponse()
  }

  lastRequestTime.set(roomId, now)

  if (!cachedModel) {
    cachedModel = await getAvailableModel()
    console.log('ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:', cachedModel)
  }

  const modelName = cachedModel || 'models/gemini-2.5-flash'
  const apiUrl = `${GEMINI_API_BASE}/${modelName}:generateContent`

  try {
    const response = await fetch(`${apiUrl}?key=${GEMINI_API_KEY}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: `ë‹¹ì‹ ì€ "${roomName}" ì±„íŒ…ë°©ì˜ ì¹œê·¼í•œ AI ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìë“¤ê³¼ ìì—°ìŠ¤ëŸ½ê³  ì¬ë¯¸ìˆê²Œ ëŒ€í™”í•˜ì„¸ìš”.\n\nì‚¬ìš©ì ë©”ì‹œì§€: ${userMessage}`,
              },
            ],
          },
        ],
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 8192,
        },
      }),
    })

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}))
      console.error('Gemini API ì˜¤ë¥˜:', errorData)
      
      if (response.status === 401 || response.status === 403) {
        console.error('Gemini API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
        return getRandomFallbackResponse()
      } else if (response.status === 404) {
        console.error('Gemini ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        console.error('ì‹œë„í•œ ëª¨ë¸:', modelName)
        console.error('API URL:', apiUrl)
        
        cachedModel = null
        const fallbackModel = await getAvailableModel()
        if (fallbackModel && fallbackModel !== modelName) {
          console.log('ëŒ€ì²´ ëª¨ë¸ ì‹œë„:', fallbackModel)
          cachedModel = fallbackModel
          return generateAIResponse(userMessage, roomName, roomId)
        }
        
        return getRandomFallbackResponse()
      } else if (response.status === 429) {
        console.warn('API ì‚¬ìš©ëŸ‰ í•œë„ ì´ˆê³¼. ê¸°ë³¸ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.')
        lastRequestTime.set(roomId, now + 120000)
        return getRandomFallbackResponse()
      } else {
        console.error(`Gemini API ì˜¤ë¥˜: ${response.status}`)
        return getRandomFallbackResponse()
      }
    }

    const data = await response.json()
    const candidate = data.candidates?.[0]
    
    if (!candidate) {
      return getRandomFallbackResponse()
    }

    const parts = candidate.content?.parts || []
    const fullText = parts
      .map(part => part.text || '')
      .join('')
      .trim()

    if (!fullText) {
      return getRandomFallbackResponse()
    }

    if (candidate.finishReason === 'MAX_TOKENS') {
      console.warn('ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì¸í•´ ì˜ë ¸ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
    }

    return fullText
  } catch (error) {
    console.error('AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:', error)
    return getRandomFallbackResponse()
  }
}

export default generateAIResponse
